\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\zref@newlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{elz-topological}
\citation{reeb-survey}
\citation{cohen2007stability}
\citation{bauer2014measuring}
\citation{de2016categorified}
\citation{di2016edit}
\citation{rubner2000earth}
\gdef\@authornum{1}
\gdef\@authornum{2}
\babel@aux{USenglish}{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\citation{hm-fast}
\citation{CK-decomposition}
\citation{krauthgamer2005black}
\citation{althofer1993sparse}
\citation{smid_2009}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:1st_example}{{1}{3}{The compute distances are shown as edges in a graph. Note that the exact distance of $p_1$ and $p_2$ is unknown. The shortest path from $p_1$ to $p_2$ has length $9$, which clearly constitutes an upper bound on the distance by triangle inequality. However, we can also infer that $\dist (p_1,p_2)\geq 3$: otherwise, the path from $p_3$ to $p_4$ via $p_1$ and $p_2$ would be shorter than the edge $(p_3,p_4)$, again contradicting triangle inequality.\relax }{figure.caption.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Background and Definitions}{3}{section.2}}
\newlabel{lem:packing_lemma}{{1}{3}{}{theorem.2.1}{}}
\citation{cal-kos-wspd}
\citation{hm-fast}
\citation{cal-kos-wspd}
\citation{cover-trees}
\citation{althofer1993sparse}
\citation{althofer1993sparse}
\citation{farshi2009experimental}
\@writefile{toc}{\contentsline {section}{\numberline {3}Algorithms for spanner construction}{4}{section.3}}
\newlabel{alg:greedy_spanner}{{0}{4}{Algorithms for spanner construction}{section.3}{}}
\newlabel{alg:blind_spanner}{{0}{5}{Algorithms for spanner construction}{section.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Experiments on spanners}{6}{section.4}}
\gdef \ET@a@i {198.29314pt}
\citation{farshi2009experimental}
\citation{hp-book}
\citation{farshi2009experimental}
\newlabel{fig:spanner_sparseness}{{2}{7}{Number of edges in blind spanners generated by different variants of the blind algorithm. Greedy non-blind algorithm and WSPD algorithm are included for comparison. The plot is for normally distributed points in dimension 2, $\eps = 0.1$.\relax }{figure.caption.2}{}}
\newlabel{tbl:regr_coeff_spanner}{{1}{7}{Estimated exponents in the $|E|= C |V|^\alpha $ dependence of the number of edges on the number of points. The data is for $\eps = 0.1$ and for uniform points.\relax }{table.caption.7}{}}
\newlabel{fig:spanner_ratio}{{3}{8}{Ratio \# edges / \# points for different variants of spanner algorithms. The plot is for normally distributed points in dimension 2, $\eps = 0.1$.\relax }{figure.caption.3}{}}
\newlabel{fig:blind_greedy_only}{{4}{8}{Results of blind greedy spanner for different dimensions.\relax }{figure.caption.4}{}}
\newlabel{fig:blind_rbr_variants}{{5}{9}{Comparison of the four variants of \textsc {BlindRandom} algorithm.\relax }{figure.caption.5}{}}
\newlabel{fig:spanner_eps_dependence}{{6}{9}{Number of edges in the blind greedy and greedy spanners for different values of $\eps $. Data is for 400 normally distributed points in $\R ^2$ and $\R ^3$.\relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Approximate nearest neighbors}{10}{section.5}}
\newlabel{sec:ann}{{5}{10}{Approximate nearest neighbors}{section.5}{}}
\newlabel{alg:ann_blind}{{0}{10}{Approximate nearest neighbors}{section.5}{}}
\newlabel{thm:ann_bound}{{2}{10}{}{theorem.5.2}{}}
\newlabel{lem:bound_lemma}{{3}{11}{}{theorem.5.3}{}}
\newlabel{fig:ann_illustration}{{7}{11}{First two steps of the ANN algorithm. First $p_1$ is chosen as the current candidate, and we must compute $\dist (p_2, q)$. After that the algorithm will not compute distance to any of the points inside the heavily shaded ball or outside the lightly shaded ball that are centered at $p_2$, because their lower bounds allow us to discard them. Note that the point $p_5$, which is closer to $q$ than $p_1$, also will not be a candidate, and at least one of the points $p_6,p_7,p_8,p_9$ in the annulus between the dashed and solid circle, which are further from $q$ than $p_5$, will be chosen as $c$. This shows that in our algorithm the distance from the candidate to $q$ can drop \textit {slower} than in the bruteforce algorithm, thus Theorem \ref {thm:ann_bound} does not immediately follow from standard backwards analysis. The small black ball between the dashed circle and the solid circle has radius $v_1 \eps / (1 + \eps )$; it is the ball that we use in the packing argument, because it is smaller than any of the lightly shaded balls that correspond to points like $p_2$ and $p_4$, that is, the points that do not improve $v$.\relax }{figure.caption.8}{}}
\citation{seidel-backwards}
\newlabel{lem:sequence_lemma}{{4}{12}{}{theorem.5.4}{}}
\newlabel{fig:exact_bad_example}{{8}{12}{Example of point set where exact nearest neighbor search cannot be accelerated by maintaining bounds. The exact nearest neighbor is the point $p_1$, next point $p_i$ is placed in the curvilinear triange formed by the balls around the query point, $p_2$ and $p_{i-1}$. Even verifying that $p_1$ is the true nearest neighbor cannot be done without computing all distances $\dist (p_i,q)$. Indeed, every computed $\dist (p_i,q)$ allows to exclude the region in the corresponding ball around $p_i$, but all these balls contain only one $p_i$.\relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Experiments on approximate nearest neighbors}{13}{section.6}}
\bibdata{bib}
\newlabel{fig:ann_const_ratio}{{9}{14}{Ratio $\log (\mbox {computed distances}) / n$ for ANN algorithm. Data is for uniformly distributed points.\relax }{figure.caption.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusion and future work}{14}{section.7}}
\newlabel{sec:conclusion}{{7}{14}{Conclusion and future work}{section.7}{}}
\setcounter {socglastlinecounter}{456}
\bibcite{althofer1993sparse}{1}
\bibcite{bauer2014measuring}{2}
\bibcite{cover-trees}{3}
\bibcite{reeb-survey}{4}
\bibcite{CK-decomposition}{5}
\bibcite{cal-kos-wspd}{6}
\bibcite{cohen2007stability}{7}
\bibcite{de2016categorified}{8}
\bibcite{di2016edit}{9}
\bibcite{elz-topological}{10}
\bibcite{farshi2009experimental}{11}
\bibcite{hm-fast}{12}
\bibcite{hp-book}{13}
\bibcite{krauthgamer2005black}{14}
\newlabel{fig:ann_dimension_dependence}{{10}{15}{Number of computed distances for different dimensions. Points are chosen uniformly, $\eps = 0.01$.\relax }{figure.caption.11}{}}
\bibcite{rubner2000earth}{15}
\bibcite{seidel-backwards}{16}
\bibcite{smid_2009}{17}
\bibstyle{plain}
\newlabel{LastPage}{{}{16}{}{page.16}{}}
\xdef\lastpage@lastpage{16}
\xdef\lastpage@lastpageHy{16}
